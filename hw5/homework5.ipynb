{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Vis, HW 5\n",
    "*Adapted from COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*\n",
    "\n",
    "Due: July 11\n",
    "\n",
    "In this homework, you will use classification methods to classify handwritten digits (Part 1) and predict the popularity of online news (Part 2). We hope these exercises will give you an idea of the broad usage of classificaiton methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and setup \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree, svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1: MNIST handwritten digits\n",
    "\n",
    "THE MNIST handwritten digit dataset consists of images of handwritten digits, together with labels indicating which digit is in each image. You will see that images are just matrices with scalar values, and that we can use all the classifcation algorithms we studied on them.  We saw these in class when we looked at clustering methods.\n",
    "\n",
    "Becaue both the features and the labels are present in this dataset (and labels for large datasets are generally difficult/expensive to obtain), this dataset is frequently used as a benchmark to compare various classification methods. \n",
    "For example, [this webpage](http://yann.lecun.com/exdb/mnist/) gives a comparison of a variety of different classification methods on MNIST (Note that the tests on this website are for higher resolution images than we'll use.) \n",
    "\n",
    "In this problem, we'll use scikit-learn to compare classification methods on the MNIST dataset. \n",
    "\n",
    "There are several versions of the MNIST dataset. We'll use the one that is built-into scikit-learn, described [here](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). \n",
    "\n",
    "* Classes: 10 (one for each digit)\n",
    "* Samples total: 1797\n",
    "* Samples per class: $\\approx$180\n",
    "* Dimensionality: 64 (8 pixels by 8 pixels)\n",
    "* Features: integers 0-16 (grayscale value; 0 is white, 16 is black)\n",
    "\n",
    "Here are some examples of the images. Note that the digits have been size-normalized and centered in a fixed-size ($8\\times8$ pixels) image.\n",
    "\n",
    "<img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_digits_classification_001.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we will scale the data before running them through our algorithms, which will also alter their appearance when we plot them. You can read details about scaling and why it's important [here](http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "n_digits: 10, n_samples 1797, n_features 64\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X = scale(digits.data)\n",
    "y = digits.target\n",
    "print(type(X))\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "n_digits = len(np.unique(digits.target))\n",
    "print(\"n_digits: %d, n_samples %d, n_features %d\" % (n_digits, n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "The raw data\n",
      "[[  0.   0.   5.  13.   9.   1.   0.   0.]\n",
      " [  0.   0.  13.  15.  10.  15.   5.   0.]\n",
      " [  0.   3.  15.   2.   0.  11.   8.   0.]\n",
      " [  0.   4.  12.   0.   0.   8.   8.   0.]\n",
      " [  0.   5.   8.   0.   0.   9.   8.   0.]\n",
      " [  0.   4.  11.   0.   1.  12.   7.   0.]\n",
      " [  0.   2.  14.   5.  10.  12.   0.   0.]\n",
      " [  0.   0.   6.  13.  10.   0.   0.   0.]]\n",
      "===\n",
      "The scaled data\n",
      "[ 0.         -0.33501649 -0.04308102  0.27407152 -0.66447751 -0.84412939\n",
      " -0.40972392 -0.12502292 -0.05907756 -0.62400926  0.4829745   0.75962245\n",
      " -0.05842586  1.12772113  0.87958306 -0.13043338 -0.04462507  0.11144272\n",
      "  0.89588044 -0.86066632 -1.14964846  0.51547187  1.90596347 -0.11422184\n",
      " -0.03337973  0.48648928  0.46988512 -1.49990136 -1.61406277  0.07639777\n",
      "  1.54181413 -0.04723238  0.          0.76465553  0.05263019 -1.44763006\n",
      " -1.73666443  0.04361588  1.43955804  0.         -0.06134367  0.8105536\n",
      "  0.63011714 -1.12245711 -1.06623158  0.66096475  0.81845076 -0.08874162\n",
      " -0.03543326  0.74211893  1.15065212 -0.86867056  0.11012973  0.53761116\n",
      " -0.75743581 -0.20978513 -0.02359646 -0.29908135  0.08671869  0.20829258\n",
      " -0.36677122 -1.14664746 -0.5056698  -0.19600752]\n",
      "===\n",
      "The digit\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# this is what one digit (a zero) looks like\n",
    "print(\"===\\nThe raw data\")\n",
    "print(digits.images[0])\n",
    "print(\"===\\nThe scaled data\")\n",
    "print(X[0])\n",
    "print(\"===\\nThe digit\")\n",
    "print(digits.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAJCCAYAAAA/cOj0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng+MvYD3NDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a156d7da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (10, 10))    \n",
    "for ii in np.arange(25):\n",
    "    plt.subplot(5, 5, ii+1)\n",
    "    plt.imshow(np.reshape(X[ii,:],(8,8)), cmap='Greys',interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might find [this webpage](http://scikit-learn.org/stable/tutorial/basic/tutorial.html) helpful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Classification with Support Vector Machines (SVM)\n",
    "\n",
    "1. Split the data into a training and test set using the command \n",
    "```\n",
    "train_test_split(X, y, random_state=1, test_size=0.8)\n",
    "```\n",
    "+ Use SVM with an `rbf` kernel and parameter `C=100` to build a classifier using the *training dataset*.\n",
    "+ Using the *test dataset*, evaluate the accuracy of the model. Again using the *test dataset*, compute the confusion matrix. What is the most common mistake that the classifier makes? \n",
    "+ Print all of these misclassified digits as images. \n",
    "+ Using the 'cross_val_score' function, evaluate the accuracy of the SVM for 100 different values of the parameter C between 1 and 500. What is the best value? \n",
    "+ Try to train and test the algorithm on the raw (non-scaled) data. What's your accuracy score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Prediction with k-nearest neighbors\n",
    "Repeat task 1.1 using k-nearest neighbors (k-NN). In part 1, use k=10. In part 3, find the best value of k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Popularity of online news\n",
    "\n",
    "For this problem, you will use classification tools to predict the popularity of online news based on attributes such as the length of the article, the number of images, the day of the week that the article was published, and some variables related to the content of the article. You can learn details about the datasetat the\n",
    "[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity). \n",
    "This dataset was first used in the following conference paper: \n",
    "\n",
    "K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. *Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence* (2015).\n",
    "\n",
    "The dataset contains variables describing 39,644 articles published between January 7, 2013 and Januyary 7, 2015 on the news website, [Mashable](http://mashable.com/). \n",
    "There are 61 variables associated with each article. Of these, 58 are *predictor* variables, 2 are variables that we will not use (url and timedelta), and finally the number of shares of each article. The number of shares is what we will use to define whether or not the article was *popular*, which is what we will try to predict. You should read about the predictor variables in the file *OnlineNewsPopularity.names*. Further details about the collection and processing of the articles can be found in the conference paper. \n",
    "\n",
    "\n",
    "### Task 2.1 Import the data \n",
    "* Use the pandas.read_csv() function to import the dataset.\n",
    "* To us[scikit-learn](http://scikit-learn.org), we'll need to save the data as a numpy array. Use the *DataFrame.as_matrix()* command to export the predictor variables as a numpy array called *X* this array should not include our target variable (the number of shares). We don't need the url and timedelta, so let's drop these columns. \n",
    "* Export the number of shares as a separate numpy array, called *shares*. We'll define an article to be popular if it received more shares than the median number of shares. Create a binary numpy array, *y*, which indicates whether or not each article is popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here.  Note the data and description are in the OnlineNewsPopularity directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 Exploratory data analysis \n",
    "\n",
    "First check to see if the values are reasonable. What are the min, median, and maximum number of shares? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3 Classification using k-NN\n",
    "\n",
    "Develop a k-NN classification model for the data. Use cross validation to choose the best value of k. What is the best accuracy you can obtain on the test data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4 Classification using SVM\n",
    "\n",
    "Develop a support vector machine classification model for the data. \n",
    " \n",
    " * SVM is computationally expensive, so start by using only a fraction of the data, say 5,000 articles. \n",
    " * Experimt with different Cs. Which is the best value for C?\n",
    "\n",
    "Note that it takes multiple minutes per value of C to run on the whole dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5 Classification using decision trees\n",
    "\n",
    "Develop a decision tree classification model for the data. \n",
    "\n",
    "Use cross validation to choose good values of the max tree depth (*max_depth*) and minimum samples split (*min_samples_split*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6 Describe your findings\n",
    "1. Which method (k-NN, SVM, Decision Tree) worked best?\n",
    "+ How did different parameters influence the accuracy?\n",
    "+ Which model is easiest do interpret?\n",
    "+ How would you interpret your results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Solution:** TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
