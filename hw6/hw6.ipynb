{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 & 2: Data acquisition and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(paths):\n",
    "    \"\"\" Extracts features and labels from a dataframe.\n",
    "\n",
    "    Args: \n",
    "        path: A list of paths to a collection of .csv's in the following dataset:\n",
    "            https://archive.ics.uci.edu/ml/datasets/Character+Font+Images\n",
    "\n",
    "    Returns:\n",
    "        X: A #samples x 20 x 20 numpy array containing the pixel data\n",
    "           for the font samples. The pixel values are originally grayscale\n",
    "           [0, 255] but scaled to the range [0, 1].\n",
    "\n",
    "        y: A numpy array containing the ascii code for each of the sample images.\n",
    "    \"\"\"\n",
    "    cols = [\"r\"+str(x)+\"c\"+str(y) for x in range(20) for y in range(20)]\n",
    "    dfs = []\n",
    "    for path in paths:\n",
    "        df = pd.read_csv(path)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    features = df[cols].copy()\n",
    "    scale = np.vectorize(lambda x: x / 255)\n",
    "    X = scale(np.reshape(features.values, features.shape[0] * features.shape[1]))\n",
    "    X = np.reshape(X, (-1, 20, 20, 1))\n",
    "    y = df['m_label'].copy().as_matrix()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def convert_to_one_hot(y, unique_chars):\n",
    "    \"\"\" Returns a nSamples x nUniqueCharacters array which is a \n",
    "        one-hot representation of y.\n",
    "\n",
    "    Args:\n",
    "        y: A 1D array containing categorical labels.\n",
    "        \n",
    "        unique_chars: a list of the possible values in y.\n",
    "\n",
    "    Returns:\n",
    "        one_hot_rep: a one-hot representation of y.\n",
    "    \"\"\"\n",
    "    one_hot_rep = []\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(unique_chars) }\n",
    "    for label in y:\n",
    "        one_hot = [0 for x in range(len(unique_chars))]\n",
    "        one_hot[char_to_ix[label]] = 1\n",
    "        one_hot_rep.append(one_hot)\n",
    "    return one_hot_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build a keras network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\"fonts/AGENCY.csv\"]\n",
    "X, y = import_data(data_paths)\n",
    "unique_chars = list(set(y))\n",
    "y = convert_to_one_hot(y, unique_chars)\n",
    "\n",
    "model = Sequential()\n",
    "# Layer 1: Convolution 2D layer with relu activations\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(20, 20, 1)))\n",
    "# Layer 2: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 3: Convolution\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "# Layer 4: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 5: Flatten\n",
    "model.add(Flatten())\n",
    "# Layer 6: Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Layer 7: Dense with relu activation\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# Layer 8: Dense with softmax activation\n",
    "model.add(Dense(len(unique_chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Exploration and Evaluation\n",
    "\n",
    "Evaluate the network using cross validation (splitting data into training/testing). What is its accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 5.5386 - acc: 0.0014\n",
      "Epoch 2/50\n",
      "702/702 [==============================] - 0s 584us/step - loss: 5.4475 - acc: 0.0214\n",
      "Epoch 3/50\n",
      "702/702 [==============================] - 0s 598us/step - loss: 4.9442 - acc: 0.0641\n",
      "Epoch 4/50\n",
      "702/702 [==============================] - 0s 588us/step - loss: 4.0023 - acc: 0.1496\n",
      "Epoch 5/50\n",
      "702/702 [==============================] - 0s 621us/step - loss: 3.1377 - acc: 0.2593 0s - loss: 3.0619 - acc: 0.\n",
      "Epoch 6/50\n",
      "702/702 [==============================] - 0s 615us/step - loss: 2.5994 - acc: 0.3276\n",
      "Epoch 7/50\n",
      "702/702 [==============================] - 0s 598us/step - loss: 2.2018 - acc: 0.3932\n",
      "Epoch 8/50\n",
      "702/702 [==============================] - 0s 605us/step - loss: 1.9504 - acc: 0.4330\n",
      "Epoch 9/50\n",
      "702/702 [==============================] - 0s 632us/step - loss: 1.8145 - acc: 0.4530 0s - loss: 1.5618 - acc: \n",
      "Epoch 10/50\n",
      "702/702 [==============================] - 0s 624us/step - loss: 1.6686 - acc: 0.4972\n",
      "Epoch 11/50\n",
      "702/702 [==============================] - 0s 608us/step - loss: 1.5536 - acc: 0.4972\n",
      "Epoch 12/50\n",
      "702/702 [==============================] - 0s 620us/step - loss: 1.4056 - acc: 0.5613\n",
      "Epoch 13/50\n",
      "702/702 [==============================] - 0s 625us/step - loss: 1.3214 - acc: 0.5741\n",
      "Epoch 14/50\n",
      "702/702 [==============================] - 0s 637us/step - loss: 1.3188 - acc: 0.5726\n",
      "Epoch 15/50\n",
      "702/702 [==============================] - 0s 626us/step - loss: 1.1798 - acc: 0.6168\n",
      "Epoch 16/50\n",
      "702/702 [==============================] - 0s 649us/step - loss: 1.2031 - acc: 0.6097\n",
      "Epoch 17/50\n",
      "702/702 [==============================] - 1s 731us/step - loss: 1.1431 - acc: 0.6040\n",
      "Epoch 18/50\n",
      "702/702 [==============================] - 0s 631us/step - loss: 1.0967 - acc: 0.6353\n",
      "Epoch 19/50\n",
      "702/702 [==============================] - 0s 664us/step - loss: 1.0651 - acc: 0.6311\n",
      "Epoch 20/50\n",
      "702/702 [==============================] - 0s 641us/step - loss: 0.9973 - acc: 0.6595\n",
      "Epoch 21/50\n",
      "702/702 [==============================] - 0s 647us/step - loss: 0.9493 - acc: 0.6823\n",
      "Epoch 22/50\n",
      "702/702 [==============================] - 0s 647us/step - loss: 0.9170 - acc: 0.6781\n",
      "Epoch 23/50\n",
      "702/702 [==============================] - 0s 647us/step - loss: 0.9147 - acc: 0.6952\n",
      "Epoch 24/50\n",
      "702/702 [==============================] - 0s 636us/step - loss: 0.8785 - acc: 0.6994\n",
      "Epoch 25/50\n",
      "702/702 [==============================] - 0s 637us/step - loss: 0.8717 - acc: 0.6980\n",
      "Epoch 26/50\n",
      "702/702 [==============================] - 0s 661us/step - loss: 0.8065 - acc: 0.7123\n",
      "Epoch 27/50\n",
      "702/702 [==============================] - 0s 628us/step - loss: 0.8900 - acc: 0.6823\n",
      "Epoch 28/50\n",
      "702/702 [==============================] - 1s 818us/step - loss: 0.7822 - acc: 0.7308 0s - loss: 0.7483 - acc: \n",
      "Epoch 29/50\n",
      "702/702 [==============================] - 1s 928us/step - loss: 0.7710 - acc: 0.7151\n",
      "Epoch 30/50\n",
      "702/702 [==============================] - 1s 969us/step - loss: 0.7729 - acc: 0.7336\n",
      "Epoch 31/50\n",
      "702/702 [==============================] - 1s 948us/step - loss: 0.7424 - acc: 0.7393\n",
      "Epoch 32/50\n",
      "702/702 [==============================] - 1s 713us/step - loss: 0.7145 - acc: 0.7507\n",
      "Epoch 33/50\n",
      "702/702 [==============================] - 0s 697us/step - loss: 0.7183 - acc: 0.7493\n",
      "Epoch 34/50\n",
      "702/702 [==============================] - 0s 679us/step - loss: 0.6819 - acc: 0.7550 0s - loss: 0.6597 - acc: 0\n",
      "Epoch 35/50\n",
      "702/702 [==============================] - 0s 663us/step - loss: 0.6786 - acc: 0.7536\n",
      "Epoch 36/50\n",
      "702/702 [==============================] - 1s 834us/step - loss: 0.6603 - acc: 0.7678\n",
      "Epoch 37/50\n",
      "702/702 [==============================] - 1s 850us/step - loss: 0.5961 - acc: 0.7778 0s - loss: 0.5453 - acc: 0\n",
      "Epoch 38/50\n",
      "702/702 [==============================] - 0s 701us/step - loss: 0.6371 - acc: 0.7735\n",
      "Epoch 39/50\n",
      "702/702 [==============================] - 1s 727us/step - loss: 0.6467 - acc: 0.7692\n",
      "Epoch 40/50\n",
      "702/702 [==============================] - 1s 733us/step - loss: 0.5502 - acc: 0.8191\n",
      "Epoch 41/50\n",
      "702/702 [==============================] - 0s 681us/step - loss: 0.5814 - acc: 0.7721\n",
      "Epoch 42/50\n",
      "702/702 [==============================] - 1s 747us/step - loss: 0.5617 - acc: 0.8034\n",
      "Epoch 43/50\n",
      "702/702 [==============================] - 0s 555us/step - loss: 0.5948 - acc: 0.7949\n",
      "Epoch 44/50\n",
      "702/702 [==============================] - 0s 530us/step - loss: 0.5740 - acc: 0.7892\n",
      "Epoch 45/50\n",
      "702/702 [==============================] - 0s 532us/step - loss: 0.5553 - acc: 0.8134\n",
      "Epoch 46/50\n",
      "702/702 [==============================] - 0s 547us/step - loss: 0.5101 - acc: 0.8205\n",
      "Epoch 47/50\n",
      "702/702 [==============================] - 0s 544us/step - loss: 0.5074 - acc: 0.8248\n",
      "Epoch 48/50\n",
      "702/702 [==============================] - 0s 585us/step - loss: 0.5184 - acc: 0.8048\n",
      "Epoch 49/50\n",
      "702/702 [==============================] - 0s 562us/step - loss: 0.5081 - acc: 0.8063\n",
      "Epoch 50/50\n",
      "702/702 [==============================] - 0s 555us/step - loss: 0.5203 - acc: 0.7934\n",
      "702/702 [==============================] - 1s 1ms/step\n",
      "Train accuracy: 0.890313389464\n",
      "302/302 [==============================] - 0s 183us/step\n",
      "Test accuracy: 0.447019867944\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(np.array(x_train), np.array(y_train), epochs=50, batch_size=32)  \n",
    "score = model.evaluate(np.array(x_train), np.array(y_train), batch_size=32)\n",
    "print(\"Train accuracy:\", score[1])\n",
    "score = model.evaluate(np.array(x_test), np.array(y_test), batch_size=32)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train a different network topology (add more convolution/dropout layers, explore other types/sizes of layer). Try to find a topology that works better than the one described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "702/702 [==============================] - 2s 4ms/step - loss: 5.5435 - acc: 0.0014\n",
      "Epoch 2/50\n",
      "702/702 [==============================] - 0s 610us/step - loss: 5.4492 - acc: 0.0128\n",
      "Epoch 3/50\n",
      "702/702 [==============================] - 0s 598us/step - loss: 5.0451 - acc: 0.0370\n",
      "Epoch 4/50\n",
      "702/702 [==============================] - 1s 745us/step - loss: 4.2595 - acc: 0.1211\n",
      "Epoch 5/50\n",
      "702/702 [==============================] - 0s 642us/step - loss: 3.4957 - acc: 0.1781\n",
      "Epoch 6/50\n",
      "702/702 [==============================] - 1s 760us/step - loss: 2.9370 - acc: 0.2578\n",
      "Epoch 7/50\n",
      "702/702 [==============================] - 1s 737us/step - loss: 2.5634 - acc: 0.3248\n",
      "Epoch 8/50\n",
      "702/702 [==============================] - 0s 656us/step - loss: 2.2813 - acc: 0.3803\n",
      "Epoch 9/50\n",
      "702/702 [==============================] - 1s 745us/step - loss: 2.0608 - acc: 0.3974\n",
      "Epoch 10/50\n",
      "702/702 [==============================] - 0s 629us/step - loss: 1.8901 - acc: 0.4288\n",
      "Epoch 11/50\n",
      "702/702 [==============================] - 0s 637us/step - loss: 1.7692 - acc: 0.4573\n",
      "Epoch 12/50\n",
      "702/702 [==============================] - 0s 678us/step - loss: 1.6669 - acc: 0.4687\n",
      "Epoch 13/50\n",
      "702/702 [==============================] - 1s 912us/step - loss: 1.5851 - acc: 0.5199\n",
      "Epoch 14/50\n",
      "702/702 [==============================] - 1s 771us/step - loss: 1.4725 - acc: 0.5271\n",
      "Epoch 15/50\n",
      "702/702 [==============================] - 0s 665us/step - loss: 1.4572 - acc: 0.5399\n",
      "Epoch 16/50\n",
      "702/702 [==============================] - 0s 641us/step - loss: 1.3700 - acc: 0.5484\n",
      "Epoch 17/50\n",
      "702/702 [==============================] - 0s 616us/step - loss: 1.2864 - acc: 0.5798\n",
      "Epoch 18/50\n",
      "702/702 [==============================] - 0s 651us/step - loss: 1.2919 - acc: 0.5741\n",
      "Epoch 19/50\n",
      "702/702 [==============================] - 0s 661us/step - loss: 1.1728 - acc: 0.6140\n",
      "Epoch 20/50\n",
      "702/702 [==============================] - 0s 629us/step - loss: 1.1808 - acc: 0.6140\n",
      "Epoch 21/50\n",
      "702/702 [==============================] - 0s 633us/step - loss: 1.0856 - acc: 0.6353\n",
      "Epoch 22/50\n",
      "702/702 [==============================] - 0s 662us/step - loss: 1.0765 - acc: 0.6453\n",
      "Epoch 23/50\n",
      "702/702 [==============================] - 0s 631us/step - loss: 1.0776 - acc: 0.6311\n",
      "Epoch 24/50\n",
      "702/702 [==============================] - 0s 635us/step - loss: 0.9653 - acc: 0.6795\n",
      "Epoch 25/50\n",
      "702/702 [==============================] - 0s 672us/step - loss: 1.0111 - acc: 0.6724\n",
      "Epoch 26/50\n",
      "702/702 [==============================] - 0s 623us/step - loss: 0.9510 - acc: 0.6524\n",
      "Epoch 27/50\n",
      "702/702 [==============================] - 0s 679us/step - loss: 0.9362 - acc: 0.6610\n",
      "Epoch 28/50\n",
      "702/702 [==============================] - 0s 648us/step - loss: 0.9595 - acc: 0.6738\n",
      "Epoch 29/50\n",
      "702/702 [==============================] - 0s 672us/step - loss: 0.9127 - acc: 0.6766\n",
      "Epoch 30/50\n",
      "702/702 [==============================] - 0s 646us/step - loss: 0.8705 - acc: 0.6937\n",
      "Epoch 31/50\n",
      "702/702 [==============================] - 0s 652us/step - loss: 0.8123 - acc: 0.7094\n",
      "Epoch 32/50\n",
      "702/702 [==============================] - 1s 742us/step - loss: 0.8259 - acc: 0.7123\n",
      "Epoch 33/50\n",
      "702/702 [==============================] - 1s 896us/step - loss: 0.8385 - acc: 0.7094\n",
      "Epoch 34/50\n",
      "702/702 [==============================] - 1s 822us/step - loss: 0.8110 - acc: 0.7265\n",
      "Epoch 35/50\n",
      "702/702 [==============================] - 1s 821us/step - loss: 0.7944 - acc: 0.7137\n",
      "Epoch 36/50\n",
      "702/702 [==============================] - 0s 687us/step - loss: 0.7496 - acc: 0.7194\n",
      "Epoch 37/50\n",
      "702/702 [==============================] - 1s 782us/step - loss: 0.7750 - acc: 0.7208\n",
      "Epoch 38/50\n",
      "702/702 [==============================] - 0s 668us/step - loss: 0.7503 - acc: 0.7265\n",
      "Epoch 39/50\n",
      "702/702 [==============================] - 1s 748us/step - loss: 0.7544 - acc: 0.7194\n",
      "Epoch 40/50\n",
      "702/702 [==============================] - 0s 666us/step - loss: 0.7232 - acc: 0.7479\n",
      "Epoch 41/50\n",
      "702/702 [==============================] - 0s 672us/step - loss: 0.6934 - acc: 0.7621\n",
      "Epoch 42/50\n",
      "702/702 [==============================] - 0s 699us/step - loss: 0.6869 - acc: 0.7621\n",
      "Epoch 43/50\n",
      "702/702 [==============================] - 1s 736us/step - loss: 0.7089 - acc: 0.7450\n",
      "Epoch 44/50\n",
      "702/702 [==============================] - 1s 821us/step - loss: 0.6253 - acc: 0.7920\n",
      "Epoch 45/50\n",
      "702/702 [==============================] - 1s 712us/step - loss: 0.6760 - acc: 0.7678\n",
      "Epoch 46/50\n",
      "702/702 [==============================] - 0s 684us/step - loss: 0.6558 - acc: 0.7607\n",
      "Epoch 47/50\n",
      "702/702 [==============================] - 1s 887us/step - loss: 0.6129 - acc: 0.7778\n",
      "Epoch 48/50\n",
      "702/702 [==============================] - 1s 744us/step - loss: 0.6320 - acc: 0.7707\n",
      "Epoch 49/50\n",
      "702/702 [==============================] - 1s 746us/step - loss: 0.6192 - acc: 0.7707\n",
      "Epoch 50/50\n",
      "702/702 [==============================] - 0s 701us/step - loss: 0.6124 - acc: 0.7877\n",
      "702/702 [==============================] - 1s 2ms/step\n",
      "Train accuracy: 0.871794872304\n",
      "302/302 [==============================] - 0s 294us/step\n",
      "Test accuracy: 0.413907285163\n"
     ]
    }
   ],
   "source": [
    "data_paths = [\"fonts/AGENCY.csv\"]\n",
    "X, y = import_data(data_paths)\n",
    "unique_chars = list(set(y))\n",
    "y = convert_to_one_hot(y, unique_chars)\n",
    "\n",
    "model = Sequential()\n",
    "# Layer 1: Convolution 2D layer with relu activations\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(20, 20, 1)))\n",
    "# Layer 2: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 3: Convolution\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "# Layer 4: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 5: Flatten\n",
    "model.add(Flatten())\n",
    "# Layer 6: Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Layer 7: Dense with relu activation\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# Layer 8: Dense with softmax activation\n",
    "model.add(Dense(len(unique_chars), activation='softmax'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(np.array(x_train), np.array(y_train), epochs=50, batch_size=32)  \n",
    "score = model.evaluate(np.array(x_train), np.array(y_train), batch_size=32)\n",
    "print(\"Train accuracy:\", score[1])\n",
    "score = model.evaluate(np.array(x_test), np.array(y_test), batch_size=32)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of your network with character inputs from a DIFFERENT font set. How does it perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1004/1004 [==============================] - 3s 3ms/step - loss: 5.5439 - acc: 0.0030\n",
      "Epoch 2/50\n",
      "1004/1004 [==============================] - 1s 618us/step - loss: 5.3302 - acc: 0.0219\n",
      "Epoch 3/50\n",
      "1004/1004 [==============================] - 1s 596us/step - loss: 4.1412 - acc: 0.0857\n",
      "Epoch 4/50\n",
      "1004/1004 [==============================] - 1s 637us/step - loss: 3.1156 - acc: 0.2191\n",
      "Epoch 5/50\n",
      "1004/1004 [==============================] - 1s 623us/step - loss: 2.5531 - acc: 0.2968 0s - loss: 2.6004 - acc\n",
      "Epoch 6/50\n",
      "1004/1004 [==============================] - 1s 663us/step - loss: 2.2142 - acc: 0.3586\n",
      "Epoch 7/50\n",
      "1004/1004 [==============================] - 1s 748us/step - loss: 1.9747 - acc: 0.4183\n",
      "Epoch 8/50\n",
      "1004/1004 [==============================] - 1s 675us/step - loss: 1.8442 - acc: 0.4512\n",
      "Epoch 9/50\n",
      "1004/1004 [==============================] - 1s 634us/step - loss: 1.6607 - acc: 0.4861\n",
      "Epoch 10/50\n",
      "1004/1004 [==============================] - 1s 802us/step - loss: 1.6243 - acc: 0.4861\n",
      "Epoch 11/50\n",
      "1004/1004 [==============================] - 1s 709us/step - loss: 1.4672 - acc: 0.5408\n",
      "Epoch 12/50\n",
      "1004/1004 [==============================] - 1s 655us/step - loss: 1.3965 - acc: 0.5438\n",
      "Epoch 13/50\n",
      "1004/1004 [==============================] - 1s 664us/step - loss: 1.3654 - acc: 0.5568\n",
      "Epoch 14/50\n",
      "1004/1004 [==============================] - 1s 649us/step - loss: 1.2459 - acc: 0.5857\n",
      "Epoch 15/50\n",
      "1004/1004 [==============================] - 1s 643us/step - loss: 1.2236 - acc: 0.5936\n",
      "Epoch 16/50\n",
      "1004/1004 [==============================] - 1s 673us/step - loss: 1.1433 - acc: 0.6116\n",
      "Epoch 17/50\n",
      "1004/1004 [==============================] - 1s 746us/step - loss: 1.1117 - acc: 0.6255\n",
      "Epoch 18/50\n",
      "1004/1004 [==============================] - 1s 692us/step - loss: 1.0952 - acc: 0.6275\n",
      "Epoch 19/50\n",
      "1004/1004 [==============================] - 1s 691us/step - loss: 1.0114 - acc: 0.6494\n",
      "Epoch 20/50\n",
      "1004/1004 [==============================] - 1s 646us/step - loss: 0.9665 - acc: 0.6773\n",
      "Epoch 21/50\n",
      "1004/1004 [==============================] - 1s 677us/step - loss: 0.9577 - acc: 0.6614\n",
      "Epoch 22/50\n",
      "1004/1004 [==============================] - 1s 653us/step - loss: 0.9016 - acc: 0.6803\n",
      "Epoch 23/50\n",
      "1004/1004 [==============================] - 1s 675us/step - loss: 0.9265 - acc: 0.6793\n",
      "Epoch 24/50\n",
      "1004/1004 [==============================] - 1s 655us/step - loss: 0.9034 - acc: 0.6773\n",
      "Epoch 25/50\n",
      "1004/1004 [==============================] - 1s 746us/step - loss: 0.8950 - acc: 0.7042\n",
      "Epoch 26/50\n",
      "1004/1004 [==============================] - 1s 737us/step - loss: 0.8362 - acc: 0.7012\n",
      "Epoch 27/50\n",
      "1004/1004 [==============================] - 1s 707us/step - loss: 0.8356 - acc: 0.7032\n",
      "Epoch 28/50\n",
      "1004/1004 [==============================] - 1s 657us/step - loss: 0.8028 - acc: 0.7032\n",
      "Epoch 29/50\n",
      "1004/1004 [==============================] - 1s 909us/step - loss: 0.7686 - acc: 0.7331 0s - loss: 0.7330 \n",
      "Epoch 30/50\n",
      "1004/1004 [==============================] - 1s 681us/step - loss: 0.7576 - acc: 0.7460\n",
      "Epoch 31/50\n",
      "1004/1004 [==============================] - 1s 672us/step - loss: 0.7371 - acc: 0.7321\n",
      "Epoch 32/50\n",
      "1004/1004 [==============================] - 1s 747us/step - loss: 0.7408 - acc: 0.7390\n",
      "Epoch 33/50\n",
      "1004/1004 [==============================] - 1s 787us/step - loss: 0.7083 - acc: 0.7540\n",
      "Epoch 34/50\n",
      "1004/1004 [==============================] - 1s 726us/step - loss: 0.7234 - acc: 0.7341\n",
      "Epoch 35/50\n",
      "1004/1004 [==============================] - 1s 755us/step - loss: 0.6968 - acc: 0.7361 0s - loss: 0.6638 - ac\n",
      "Epoch 36/50\n",
      "1004/1004 [==============================] - 1s 745us/step - loss: 0.6716 - acc: 0.7699\n",
      "Epoch 37/50\n",
      "1004/1004 [==============================] - 1s 743us/step - loss: 0.6518 - acc: 0.7689\n",
      "Epoch 38/50\n",
      "1004/1004 [==============================] - 1s 806us/step - loss: 0.6210 - acc: 0.7829\n",
      "Epoch 39/50\n",
      "1004/1004 [==============================] - 1s 805us/step - loss: 0.6515 - acc: 0.7530\n",
      "Epoch 40/50\n",
      "1004/1004 [==============================] - 1s 724us/step - loss: 0.6142 - acc: 0.7789\n",
      "Epoch 41/50\n",
      "1004/1004 [==============================] - 1s 819us/step - loss: 0.6290 - acc: 0.7699\n",
      "Epoch 42/50\n",
      "1004/1004 [==============================] - 1s 805us/step - loss: 0.5906 - acc: 0.7759\n",
      "Epoch 43/50\n",
      "1004/1004 [==============================] - 1s 864us/step - loss: 0.5921 - acc: 0.7859\n",
      "Epoch 44/50\n",
      "1004/1004 [==============================] - 1s 782us/step - loss: 0.5626 - acc: 0.8018\n",
      "Epoch 45/50\n",
      "1004/1004 [==============================] - 1s 791us/step - loss: 0.5773 - acc: 0.7968\n",
      "Epoch 46/50\n",
      "1004/1004 [==============================] - 1s 801us/step - loss: 0.5597 - acc: 0.7928\n",
      "Epoch 47/50\n",
      "1004/1004 [==============================] - 1s 824us/step - loss: 0.5560 - acc: 0.7898\n",
      "Epoch 48/50\n",
      "1004/1004 [==============================] - 1s 830us/step - loss: 0.5549 - acc: 0.8018\n",
      "Epoch 49/50\n",
      "1004/1004 [==============================] - 1s 809us/step - loss: 0.5639 - acc: 0.7888\n",
      "Epoch 50/50\n",
      "1004/1004 [==============================] - 1s 861us/step - loss: 0.5131 - acc: 0.8108\n",
      "1004/1004 [==============================] - 1s 1ms/step\n",
      "Train accuracy: 0.886454183504\n",
      "956/956 [==============================] - 0s 260us/step\n",
      "Test accuracy: 0.229079497908\n"
     ]
    }
   ],
   "source": [
    "train_paths = [\"fonts/AGENCY.csv\"]\n",
    "test_paths = [\"fonts/BELL.csv\"]\n",
    "x_train, y_train = import_data(train_paths)\n",
    "x_test, y_test = import_data(test_paths)\n",
    "unique_chars = list(set(y_train).union(y_test))\n",
    "y_train = convert_to_one_hot(y_train, unique_chars)\n",
    "y_test = convert_to_one_hot(y_test, unique_chars)\n",
    "\n",
    "model = Sequential()\n",
    "# Layer 1: Convolution 2D layer with relu activations\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(20, 20, 1)))\n",
    "# Layer 2: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 3: Convolution\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "# Layer 4: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 5: Flatten\n",
    "model.add(Flatten())\n",
    "# Layer 6: Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Layer 7: Dense with relu activation\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# Layer 8: Dense with softmax activation\n",
    "model.add(Dense(len(unique_chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(np.array(x_train), np.array(y_train), epochs=50, batch_size=32)  \n",
    "score = model.evaluate(np.array(x_train), np.array(y_train), batch_size=32)\n",
    "print(\"Train accuracy:\", score[1])\n",
    "score = model.evaluate(np.array(x_test), np.array(y_test), batch_size=32)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your best network on inputs from the data from at least 2 different fonts. How does your accuracy compare to the 1-font case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2287/2287 [==============================] - 4s 2ms/step - loss: 5.8043 - acc: 0.0105\n",
      "Epoch 2/50\n",
      "2287/2287 [==============================] - 2s 670us/step - loss: 4.8513 - acc: 0.0621\n",
      "Epoch 3/50\n",
      "2287/2287 [==============================] - 2s 662us/step - loss: 3.6822 - acc: 0.1740\n",
      "Epoch 4/50\n",
      "2287/2287 [==============================] - 2s 671us/step - loss: 3.0136 - acc: 0.2571\n",
      "Epoch 5/50\n",
      "2287/2287 [==============================] - 2s 665us/step - loss: 2.5779 - acc: 0.3209\n",
      "Epoch 6/50\n",
      "2287/2287 [==============================] - 2s 681us/step - loss: 2.2890 - acc: 0.3704\n",
      "Epoch 7/50\n",
      "2287/2287 [==============================] - 2s 660us/step - loss: 2.0679 - acc: 0.4066\n",
      "Epoch 8/50\n",
      "2287/2287 [==============================] - 2s 670us/step - loss: 1.8940 - acc: 0.4464\n",
      "Epoch 9/50\n",
      "2287/2287 [==============================] - 2s 701us/step - loss: 1.7406 - acc: 0.4958\n",
      "Epoch 10/50\n",
      "2287/2287 [==============================] - 2s 724us/step - loss: 1.6381 - acc: 0.5059 1s - l\n",
      "Epoch 11/50\n",
      "2287/2287 [==============================] - 2s 691us/step - loss: 1.5513 - acc: 0.5164\n",
      "Epoch 12/50\n",
      "2287/2287 [==============================] - 2s 755us/step - loss: 1.4577 - acc: 0.5536\n",
      "Epoch 13/50\n",
      "2287/2287 [==============================] - 2s 816us/step - loss: 1.3548 - acc: 0.5719\n",
      "Epoch 14/50\n",
      "2287/2287 [==============================] - 2s 877us/step - loss: 1.2781 - acc: 0.5964\n",
      "Epoch 15/50\n",
      "2287/2287 [==============================] - 2s 791us/step - loss: 1.2420 - acc: 0.5982\n",
      "Epoch 16/50\n",
      "2287/2287 [==============================] - 2s 846us/step - loss: 1.1986 - acc: 0.6148\n",
      "Epoch 17/50\n",
      "2287/2287 [==============================] - 2s 756us/step - loss: 1.1329 - acc: 0.6292\n",
      "Epoch 18/50\n",
      "2287/2287 [==============================] - 2s 789us/step - loss: 1.1193 - acc: 0.6467\n",
      "Epoch 19/50\n",
      "2287/2287 [==============================] - 2s 798us/step - loss: 1.0434 - acc: 0.6484\n",
      "Epoch 20/50\n",
      "2287/2287 [==============================] - 2s 711us/step - loss: 1.0395 - acc: 0.6528\n",
      "Epoch 21/50\n",
      "2287/2287 [==============================] - 1s 603us/step - loss: 1.0168 - acc: 0.6594\n",
      "Epoch 22/50\n",
      "2287/2287 [==============================] - 1s 588us/step - loss: 0.9396 - acc: 0.6808\n",
      "Epoch 23/50\n",
      "2287/2287 [==============================] - 1s 616us/step - loss: 0.9122 - acc: 0.6843\n",
      "Epoch 24/50\n",
      "2287/2287 [==============================] - 1s 599us/step - loss: 0.8933 - acc: 0.7040\n",
      "Epoch 25/50\n",
      "2287/2287 [==============================] - 1s 599us/step - loss: 0.8804 - acc: 0.7118\n",
      "Epoch 26/50\n",
      "2287/2287 [==============================] - 1s 600us/step - loss: 0.8669 - acc: 0.7009\n",
      "Epoch 27/50\n",
      "2287/2287 [==============================] - 1s 586us/step - loss: 0.8364 - acc: 0.7153\n",
      "Epoch 28/50\n",
      "2287/2287 [==============================] - 2s 661us/step - loss: 0.8033 - acc: 0.7245\n",
      "Epoch 29/50\n",
      "2287/2287 [==============================] - 2s 706us/step - loss: 0.7856 - acc: 0.7337\n",
      "Epoch 30/50\n",
      "2287/2287 [==============================] - 1s 593us/step - loss: 0.7699 - acc: 0.7307\n",
      "Epoch 31/50\n",
      "2287/2287 [==============================] - 1s 602us/step - loss: 0.7272 - acc: 0.7499\n",
      "Epoch 32/50\n",
      "2287/2287 [==============================] - 1s 578us/step - loss: 0.7713 - acc: 0.7394\n",
      "Epoch 33/50\n",
      "2287/2287 [==============================] - 1s 593us/step - loss: 0.7581 - acc: 0.7355\n",
      "Epoch 34/50\n",
      "2287/2287 [==============================] - 1s 596us/step - loss: 0.7307 - acc: 0.7569\n",
      "Epoch 35/50\n",
      "2287/2287 [==============================] - 1s 620us/step - loss: 0.6981 - acc: 0.7551\n",
      "Epoch 36/50\n",
      "2287/2287 [==============================] - 2s 695us/step - loss: 0.6996 - acc: 0.7608\n",
      "Epoch 37/50\n",
      "2287/2287 [==============================] - 2s 904us/step - loss: 0.6801 - acc: 0.7648 0s - loss: 0.6785 - acc:\n",
      "Epoch 38/50\n",
      "2287/2287 [==============================] - 2s 775us/step - loss: 0.6733 - acc: 0.7643\n",
      "Epoch 39/50\n",
      "2287/2287 [==============================] - 2s 822us/step - loss: 0.6493 - acc: 0.7805\n",
      "Epoch 40/50\n",
      "2287/2287 [==============================] - 2s 749us/step - loss: 0.6481 - acc: 0.7718\n",
      "Epoch 41/50\n",
      "2287/2287 [==============================] - 2s 800us/step - loss: 0.6343 - acc: 0.7827\n",
      "Epoch 42/50\n",
      "2287/2287 [==============================] - 2s 772us/step - loss: 0.6552 - acc: 0.7748\n",
      "Epoch 43/50\n",
      "2287/2287 [==============================] - 2s 867us/step - loss: 0.6234 - acc: 0.7792\n",
      "Epoch 44/50\n",
      "2287/2287 [==============================] - 2s 816us/step - loss: 0.6164 - acc: 0.7927\n",
      "Epoch 45/50\n",
      "2287/2287 [==============================] - 2s 919us/step - loss: 0.6023 - acc: 0.7901 0s - loss: 0.5880 - acc:\n",
      "Epoch 46/50\n",
      "2287/2287 [==============================] - 2s 978us/step - loss: 0.6075 - acc: 0.7910\n",
      "Epoch 47/50\n",
      "2287/2287 [==============================] - 2s 825us/step - loss: 0.5812 - acc: 0.7984\n",
      "Epoch 48/50\n",
      "2287/2287 [==============================] - 2s 885us/step - loss: 0.5917 - acc: 0.7914\n",
      "Epoch 49/50\n",
      "2287/2287 [==============================] - 2s 830us/step - loss: 0.5857 - acc: 0.7901\n",
      "Epoch 50/50\n",
      "2287/2287 [==============================] - 2s 778us/step - loss: 0.5812 - acc: 0.7941\n",
      "2287/2287 [==============================] - 1s 586us/step\n",
      "Train accuracy: 0.875819851386\n",
      "981/981 [==============================] - 0s 245us/step\n",
      "Test accuracy: 0.510703364279\n"
     ]
    }
   ],
   "source": [
    "train_paths = [\"fonts/AGENCY.csv\", \"fonts/BELL.csv\", \"fonts/TXT.csv\"]\n",
    "test_paths = [\"fonts/AGENCY.csv\", \"fonts/BELL.csv\", \"fonts/TXT.csv\"]\n",
    "X, y = import_data(train_paths)\n",
    "unique_chars = list(set(y))\n",
    "y = convert_to_one_hot(y, unique_chars)\n",
    "\n",
    "model = Sequential()\n",
    "# Layer 1: Convolution 2D layer with relu activations\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(20, 20, 1)))\n",
    "# Layer 2: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 3: Convolution\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "# Layer 4: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 5: Flatten\n",
    "model.add(Flatten())\n",
    "# Layer 6: Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Layer 7: Dense with relu activation\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# Layer 8: Dense with softmax activation\n",
    "model.add(Dense(len(unique_chars), activation='softmax'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(np.array(x_train), np.array(y_train), epochs=50, batch_size=32)  \n",
    "score = model.evaluate(np.array(x_train), np.array(y_train), batch_size=32)\n",
    "print(\"Train accuracy:\", score[1])\n",
    "score = model.evaluate(np.array(x_test), np.array(y_test), batch_size=32)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What accuracy do you see when testing with inputs from a font you didn't train on now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3268/3268 [==============================] - 4s 1ms/step - loss: 5.6857 - acc: 0.0125A: 4s - loss\n",
      "Epoch 2/50\n",
      "3268/3268 [==============================] - 3s 830us/step - loss: 4.1876 - acc: 0.1166 1s \n",
      "Epoch 3/50\n",
      "3268/3268 [==============================] - 2s 757us/step - loss: 3.1806 - acc: 0.2252 0s - loss: 3.2080 - acc: \n",
      "Epoch 4/50\n",
      "3268/3268 [==============================] - 3s 862us/step - loss: 2.6029 - acc: 0.3008\n",
      "Epoch 5/50\n",
      "3268/3268 [==============================] - 2s 676us/step - loss: 2.2586 - acc: 0.3721\n",
      "Epoch 6/50\n",
      "3268/3268 [==============================] - 3s 919us/step - loss: 2.0292 - acc: 0.4189\n",
      "Epoch 7/50\n",
      "3268/3268 [==============================] - 3s 835us/step - loss: 1.8490 - acc: 0.4446 0s - loss: 1.8307 - acc\n",
      "Epoch 8/50\n",
      "3268/3268 [==============================] - 3s 878us/step - loss: 1.7105 - acc: 0.4783\n",
      "Epoch 9/50\n",
      "3268/3268 [==============================] - 2s 736us/step - loss: 1.5781 - acc: 0.5098\n",
      "Epoch 10/50\n",
      "3268/3268 [==============================] - 3s 799us/step - loss: 1.4821 - acc: 0.5288\n",
      "Epoch 11/50\n",
      "3268/3268 [==============================] - 2s 654us/step - loss: 1.4040 - acc: 0.5560\n",
      "Epoch 12/50\n",
      "3268/3268 [==============================] - 2s 640us/step - loss: 1.3496 - acc: 0.5569\n",
      "Epoch 13/50\n",
      "3268/3268 [==============================] - 3s 793us/step - loss: 1.2573 - acc: 0.5927\n",
      "Epoch 14/50\n",
      "3268/3268 [==============================] - 2s 716us/step - loss: 1.2020 - acc: 0.6043\n",
      "Epoch 15/50\n",
      "3268/3268 [==============================] - 3s 771us/step - loss: 1.1691 - acc: 0.6095\n",
      "Epoch 16/50\n",
      "3268/3268 [==============================] - 3s 910us/step - loss: 1.1046 - acc: 0.6304\n",
      "Epoch 17/50\n",
      "3268/3268 [==============================] - 3s 858us/step - loss: 1.0723 - acc: 0.6270 1s - loss: 1.06\n",
      "Epoch 18/50\n",
      "3268/3268 [==============================] - 2s 687us/step - loss: 1.0238 - acc: 0.6606\n",
      "Epoch 19/50\n",
      "3268/3268 [==============================] - 3s 769us/step - loss: 1.0193 - acc: 0.6536\n",
      "Epoch 20/50\n",
      "3268/3268 [==============================] - 3s 842us/step - loss: 0.9877 - acc: 0.6570\n",
      "Epoch 21/50\n",
      "3268/3268 [==============================] - 2s 694us/step - loss: 0.9445 - acc: 0.6695\n",
      "Epoch 22/50\n",
      "3268/3268 [==============================] - 2s 729us/step - loss: 0.9249 - acc: 0.6836 0s - loss: 0.9272 - acc: 0.6\n",
      "Epoch 23/50\n",
      "3268/3268 [==============================] - 2s 695us/step - loss: 0.9007 - acc: 0.6897\n",
      "Epoch 24/50\n",
      "3268/3268 [==============================] - 2s 692us/step - loss: 0.8547 - acc: 0.7053\n",
      "Epoch 25/50\n",
      "3268/3268 [==============================] - 2s 694us/step - loss: 0.8539 - acc: 0.7059\n",
      "Epoch 26/50\n",
      "3268/3268 [==============================] - 2s 699us/step - loss: 0.8301 - acc: 0.7078\n",
      "Epoch 27/50\n",
      "3268/3268 [==============================] - 2s 695us/step - loss: 0.8185 - acc: 0.7179\n",
      "Epoch 28/50\n",
      "3268/3268 [==============================] - 2s 713us/step - loss: 0.8006 - acc: 0.7228\n",
      "Epoch 29/50\n",
      "3268/3268 [==============================] - 2s 727us/step - loss: 0.7899 - acc: 0.7142\n",
      "Epoch 30/50\n",
      "3268/3268 [==============================] - 2s 703us/step - loss: 0.7830 - acc: 0.7264\n",
      "Epoch 31/50\n",
      "3268/3268 [==============================] - 2s 722us/step - loss: 0.7695 - acc: 0.7267\n",
      "Epoch 32/50\n",
      "3268/3268 [==============================] - 2s 721us/step - loss: 0.7559 - acc: 0.7307 0s - loss: 0.7511 - acc:\n",
      "Epoch 33/50\n",
      "3268/3268 [==============================] - 2s 713us/step - loss: 0.7324 - acc: 0.7451\n",
      "Epoch 34/50\n",
      "3268/3268 [==============================] - 2s 721us/step - loss: 0.7411 - acc: 0.7457 0s - loss: 0.7386 \n",
      "Epoch 35/50\n",
      "3268/3268 [==============================] - 2s 713us/step - loss: 0.7231 - acc: 0.7405\n",
      "Epoch 36/50\n",
      "3268/3268 [==============================] - 2s 752us/step - loss: 0.6945 - acc: 0.7512\n",
      "Epoch 37/50\n",
      "3268/3268 [==============================] - 2s 761us/step - loss: 0.6950 - acc: 0.7494\n",
      "Epoch 38/50\n",
      "3268/3268 [==============================] - 3s 916us/step - loss: 0.6937 - acc: 0.7619\n",
      "Epoch 39/50\n",
      "3268/3268 [==============================] - 3s 891us/step - loss: 0.6623 - acc: 0.7570 0s - loss: 0.6577 - acc: \n",
      "Epoch 40/50\n",
      "3268/3268 [==============================] - 2s 737us/step - loss: 0.6641 - acc: 0.7638 1s - loss: 0.629\n",
      "Epoch 41/50\n",
      "3268/3268 [==============================] - 3s 956us/step - loss: 0.6710 - acc: 0.7659 1s - loss: 0.6359 - acc: 0. - ETA: 1s - loss\n",
      "Epoch 42/50\n",
      "3268/3268 [==============================] - 3s 998us/step - loss: 0.6235 - acc: 0.7840\n",
      "Epoch 43/50\n",
      "3268/3268 [==============================] - 3s 790us/step - loss: 0.6529 - acc: 0.7659\n",
      "Epoch 44/50\n",
      "3268/3268 [==============================] - 3s 765us/step - loss: 0.6481 - acc: 0.7693\n",
      "Epoch 45/50\n",
      "3268/3268 [==============================] - 3s 768us/step - loss: 0.6130 - acc: 0.7729\n",
      "Epoch 46/50\n",
      "3268/3268 [==============================] - 3s 820us/step - loss: 0.6228 - acc: 0.7748\n",
      "Epoch 47/50\n",
      "3268/3268 [==============================] - 2s 757us/step - loss: 0.6151 - acc: 0.7824\n",
      "Epoch 48/50\n",
      "3268/3268 [==============================] - 3s 779us/step - loss: 0.6241 - acc: 0.7748\n",
      "Epoch 49/50\n",
      "3268/3268 [==============================] - 3s 813us/step - loss: 0.6093 - acc: 0.7818 0s - loss: 0.6135 - acc:\n",
      "Epoch 50/50\n",
      "3268/3268 [==============================] - 3s 926us/step - loss: 0.5884 - acc: 0.7928\n",
      "3268/3268 [==============================] - 2s 542us/step\n",
      "Train accuracy: 0.854651162791\n",
      "1136/1136 [==============================] - 0s 349us/step\n",
      "Test accuracy: 0.221830985915\n"
     ]
    }
   ],
   "source": [
    "train_paths = [\"fonts/AGENCY.csv\", \"fonts/BELL.csv\", \"fonts/TXT.csv\"]\n",
    "test_paths = [\"fonts/SNAP.csv\"]\n",
    "x_train, y_train = import_data(train_paths)\n",
    "x_test, y_test = import_data(test_paths)\n",
    "unique_chars = list(set(y_train).union(y_test))\n",
    "y_train = convert_to_one_hot(y_train, unique_chars)\n",
    "y_test = convert_to_one_hot(y_test, unique_chars)\n",
    "\n",
    "model = Sequential()\n",
    "# Layer 1: Convolution 2D layer with relu activations\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(20, 20, 1)))\n",
    "# Layer 2: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 3: Convolution\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "# Layer 4: Max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "# Layer 5: Flatten\n",
    "model.add(Flatten())\n",
    "# Layer 6: Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Layer 7: Dense with relu activation\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# Layer 8: Dense with softmax activation\n",
    "model.add(Dense(len(unique_chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(np.array(x_train), np.array(y_train), epochs=50, batch_size=32)  \n",
    "score = model.evaluate(np.array(x_train), np.array(y_train), batch_size=32)\n",
    "print(\"Train accuracy:\", score[1])\n",
    "score = model.evaluate(np.array(x_test), np.array(y_test), batch_size=32)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
